{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has 3 main steps:\n",
    "- Step 1: Use ARC's API to conveniently run geometry optimizations and frequency calculations for ~400 reference species in preparation for BAC fitting\n",
    "    - Recommended to comment out some lines in `ARC/arc/job/trsh.py` to ensure that ARC will only only troubleshoot by changing the optimization algorithm and not be changing the LoT or the software. For example, if using Gaussian to calculate BACs at some LoT, it would be wise to comment out these [lines](https://github.com/ReactionMechanismGenerator/ARC/blob/master/arc/job/trsh.py#L837-L844) and these [lines](https://github.com/ReactionMechanismGenerator/ARC/blob/master/arc/job/trsh.py#L852-L870).\n",
    "- Step 2: Use Arkane to calculate H298 and add the values for the new LoT to our reference database\n",
    "- Step 3: Finally, use Arkane to perform BAC fitting\n",
    "\n",
    "Briefly, [ARC](https://github.com/ReactionMechanismGenerator/ARC) (Automated Rate Calculator) is a software developed by the RMG team for automating electronic structure calculations, which are then used to calculate thermochemical and kinetic parameters. Installation instructions can be found on ARC's documentation [link](https://reactionmechanismgenerator.github.io/ARC/installation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RMG-Py and ARC to Python Path (Optional)\n",
    "import sys\n",
    "# this is an example path if running the notebook on supercloud\n",
    "# replace <USERNAME> with your username\n",
    "sys.path.append(\"/home/gridsan/<USERNAME>/RMG/RMG-Py/\")\n",
    "sys.path.append(\"/home/gridsan/<USERNAME>/RMG/ARC/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from arkane.encorr.reference import ReferenceDatabase\n",
    "from arkane.ess import ess_factory\n",
    "from rmgpy.molecule import Molecule\n",
    "\n",
    "from arc import ARC\n",
    "from arc.species import ARCSpecies\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the reference database\n",
    "database = ReferenceDatabase()\n",
    "database.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0) Define ARC Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.1) Model chemistry and desired calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## USER INPUT ########################################\n",
    "parent_folder = '/home/gridsan/<USERNAME>/ARC/Projects/'\n",
    "project = 'BAC_wb97xd3_def2tzvp'\n",
    "\n",
    "ess_settings = {'qchem': ['local']}\n",
    "job_types = {'rotors': False,\n",
    "             'conformers': False,\n",
    "             'fine': False,\n",
    "             'freq': True,\n",
    "             'opt': True,\n",
    "             'sp': True,\n",
    "             }\n",
    "\n",
    "max_job_time = 500  # hours\n",
    "\n",
    "method = 'wb97x-d3'\n",
    "basis = 'def2-tzvp'\n",
    "software = 'qchem'\n",
    "model_chemistry = f'{method}/{basis}'\n",
    "\n",
    "# Set the Level of Theory\n",
    "level_of_theory = {'method': method, 'basis': basis}\n",
    "\n",
    "opt_level = level_of_theory\n",
    "freq_level = level_of_theory\n",
    "scan_level = level_of_theory\n",
    "sp_level = level_of_theory\n",
    "conformer_level = level_of_theory\n",
    "ts_guess_level = level_of_theory\n",
    "###################################### END USER INPUT ######################################\n",
    "project_dir = os.path.join(parent_folder, project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.2) Define desired species to run (RUN ONLY ONE OF THE FOLLOWING CELLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All reference species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_spcs = database.reference_sets['main']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Species with specific indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "project_spcs = database.get_species_from_index(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) Use ARC API to run the QM jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1 Determine which species need to be run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "already_done = []\n",
    "done_jobs = set()\n",
    "\n",
    "# check for completed species by seeing which have opt, freq, and sp folders.\n",
    "# if all folders are present, assume the species has completed its calculations.\n",
    "# alternatively, could check output/status.yml to get the status of each species\n",
    "for root, dirs, files in os.walk(os.path.join(project_dir, 'calcs', 'Species')):\n",
    "    dirs.sort()\n",
    "    for directory in dirs:\n",
    "        for root1, dirs1, files1 in os.walk(os.path.join(root, directory)):\n",
    "            if len(dirs1) == 3:\n",
    "                done_jobs.add(directory)\n",
    "            break\n",
    "    break\n",
    "\n",
    "already_done = list(done_jobs)\n",
    "\n",
    "spcs_to_run = []\n",
    "for ref_spcs in project_spcs:\n",
    "    if f'spcs{ref_spcs.index}' not in already_done:\n",
    "        spcs = ARCSpecies(label=f'spcs{ref_spcs.index}',\n",
    "                          adjlist=ref_spcs.adjacency_list,\n",
    "                          # default xyz is to start from the wb97mv conformer searching from Colin\n",
    "                          xyz=ref_spcs.get_default_xyz(),\n",
    "                          charge=ref_spcs.charge,\n",
    "                          multiplicity=ref_spcs.multiplicity,\n",
    "                          is_ts=ref_spcs.is_ts,\n",
    "                          )\n",
    "        spcs.mol = Molecule().from_adjacency_list(ref_spcs.adjacency_list, \n",
    "                                                  raise_atomtype_exception=False,\n",
    "                                                  raise_charge_exception=False)\n",
    "        spcs.multiplicity = ref_spcs.multiplicity\n",
    "        spcs.charge = ref_spcs.charge\n",
    "        \n",
    "        spcs_to_run.append(spcs)\n",
    "\n",
    "print(f'\\nThe following {len(done_jobs)} species are already complete: {done_jobs}')\n",
    "print(f'\\nThe following {len(spcs_to_run)} species still need to be run: {[s.label for s in spcs_to_run]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_job_paths = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2) Add path for opt/freq files (optional, if run in previous ARC job)\n",
    "- Useful if doing composite LoT in which geometry optimization + frequency calculation are at a lower LoT and single point energy is at a higher LoT. Otherwise, can skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_logs = '/home/gridsan/<USERNAME>/PATH_TO_LOG_FILES/'\n",
    "\n",
    "# Organize files by index\n",
    "qm_logs = {}\n",
    "for filename in os.listdir(path_to_logs):\n",
    "    indx = filename.split('_')[0]\n",
    "    qm_logs[indx] = os.path.join(path_to_logs, filename)\n",
    "    \n",
    "# Add files to restart dictionary\n",
    "previous_job_paths = {}\n",
    "for arc_spcs in spcs_to_run:\n",
    "    label = arc_spcs.label\n",
    "    indx = label[4:]\n",
    "    previous_job_paths[label] = {'geo': qm_logs[indx], 'freq': qm_logs[indx]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.3) Run ARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arc_species_list = spcs_to_run\n",
    "\n",
    "arc = ARC(project=project,\n",
    "          species=arc_species_list,\n",
    "          ess_settings=ess_settings,\n",
    "          job_types=job_types,\n",
    "          max_job_time=max_job_time,\n",
    "          opt_level=opt_level,\n",
    "          freq_level=freq_level,\n",
    "          scan_level=scan_level,\n",
    "          sp_level=sp_level,\n",
    "          conformer_level=conformer_level,\n",
    "          ts_guess_level=ts_guess_level,\n",
    "          compare_to_rmg=False,\n",
    "          calc_freq_factor=False,\n",
    "          running_jobs=previous_job_paths,\n",
    "          )\n",
    "\n",
    "status_dict = arc.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.4) Reorganize the raw QM output from ARC folders to new opt+freq and sp folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('freq-folder')\n",
    "os.mkdir('sp-folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running ARC above, it may struggle with a handful of species by giving negative frequencies or non-converged geometry optimizations. Read the end of the ARC log file to find the few species that had negative frequencies (if applicable). Alternatively, this code could be modified to automatically parse the frequenies from the QM output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(parent_folder, project, 'calcs', 'Species')\n",
    "no_freq = []  # these are the species that had convergence errors on opt so they never got to freq\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    # dirs is [spcs0, spcs1, ..spcs426]\n",
    "    # there are a few places that skip an index so it's not perfectly sequentially\n",
    "    dirs.sort()\n",
    "    for directory in dirs:\n",
    "        index = int(directory[4:])  # parse the index from spcs0 for example\n",
    "        for root1, dirs1, files1 in os.walk(os.path.join(root, directory)):\n",
    "            dirs1.sort()  # dirs1 should now be ['freq', 'opt', 'sp']\n",
    "            \n",
    "            # ensure no extra jobs have been run by checking there are exactly 3 folders\n",
    "            try:\n",
    "                assert len(dirs1) == 3\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(directory, dirs1)\n",
    "\n",
    "            # copy the frequency output file\n",
    "            freq_dir = dirs1[0]\n",
    "            if 'freq' not in freq_dir:\n",
    "                print(f'index {index} was missing a frequency job')\n",
    "                no_freq.append(directory)\n",
    "                break  # if no frequency job, then there will be no sp job either so just break out of this loop\n",
    "            else:\n",
    "                for root2, dirs2, files2 in os.walk(os.path.join(root1, freq_dir)):\n",
    "                    files2.sort()\n",
    "                    output = os.path.join(root2, 'output.out')\n",
    "                    dst = os.path.join('freq-folder', str(index)+ '_output.out')\n",
    "                    shutil.copy(output, dst)\n",
    "                    break\n",
    "            \n",
    "            # copy the sp output file\n",
    "            sp_dir = dirs1[2]\n",
    "            if 'sp' not in sp_dir:\n",
    "                print(f'index {index} was missing an sp job')\n",
    "            else:\n",
    "                for root2, dirs2, files2 in os.walk(os.path.join(root1, sp_dir)):\n",
    "                    files2.sort()\n",
    "                    output = os.path.join(root2, 'output.out')\n",
    "                    dst = os.path.join('sp-folder', str(index)+ '_output.out')\n",
    "                    shutil.copy(output, dst)\n",
    "                    break\n",
    "            break\n",
    "    break\n",
    "print(f'No frequencies: {no_freq}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) Use Arkane to calculate H298 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from rdkit.Chem import GetPeriodicTable\n",
    "\n",
    "from rmgpy.quantity import ScalarQuantity\n",
    "from rmgpy.statmech import HarmonicOscillator, IdealGasTranslation, LinearRotor, NonlinearRotor\n",
    "from rmgpy.thermo import ThermoData\n",
    "\n",
    "from arkane.common import symbol_by_number\n",
    "from arkane.encorr.corr import get_atom_correction, assign_frequency_scale_factor\n",
    "from arkane.encorr.reference import CalculatedDataEntry, ReferenceDatabase\n",
    "from arkane.modelchem import LevelOfTheory, CompositeLevelOfTheory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1) Define level of theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_lot = LevelOfTheory(method=method,\n",
    "                         basis=basis,\n",
    "                         software=software,\n",
    "                         )\n",
    "energy_lot = LevelOfTheory(method=method,\n",
    "                           basis=basis,\n",
    "                           software=software,\n",
    "                           )\n",
    "# could define composite LoT if applicable\n",
    "# energy_lot = CompositeLevelOfTheory(freq=freq_lot, energy=energy_lot)\n",
    "\n",
    "freq_log_dir = 'freq-folder'\n",
    "energy_log_dir = 'sp-folder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2) Define a function for using the Arkane API to calculate thermo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_to_enthalpy(freq_lot, energy_lot, freq_log, energy_log=None, temp=298.15):\n",
    "    freq_log = ess_factory(freq_log)\n",
    "    energy_log = freq_log if energy_log is None else ess_factory(energy_log)\n",
    "    \n",
    "    conformer, _ = freq_log.load_conformer()\n",
    "    # Perform quick checks\n",
    "    assert conformer.spin_multiplicity > 0\n",
    "    assert any(isinstance(mode, IdealGasTranslation) for mode in conformer.modes)\n",
    "    assert any(isinstance(mode, (LinearRotor, NonlinearRotor)) for mode in conformer.modes)\n",
    "    assert any(isinstance(mode, HarmonicOscillator) for mode in conformer.modes)\n",
    "    \n",
    "    coords, nums, masses = energy_log.load_geometry()\n",
    "    assert len(nums) > 1\n",
    "    \n",
    "    atoms = Counter([symbol_by_number[int(n)] for n in nums]) \n",
    "    conformer.coordinates = (coords, 'angstroms')\n",
    "    conformer.number = nums\n",
    "    conformer.mass = (masses, 'amu')\n",
    "    \n",
    "    freq_scale_factor = assign_frequency_scale_factor(freq_lot)\n",
    "    frequencies = conformer.modes[2].frequencies.value_si\n",
    "    for mode in conformer.modes:\n",
    "        if isinstance(mode, HarmonicOscillator):\n",
    "            mode.frequencies = (frequencies * freq_scale_factor, \"cm^-1\")\n",
    "    if freq_scale_factor == 1:\n",
    "        print('WARNING: Frequency scale factor is 1')\n",
    "    zpe_scale_factor = freq_scale_factor / 1.014\n",
    "    \n",
    "    # get electronic energy\n",
    "    energy = energy_log.load_energy(zpe_scale_factor=zpe_scale_factor)  # J/mol\n",
    "    \n",
    "    # add ZPE\n",
    "    energy += freq_log.load_zero_point_energy() * zpe_scale_factor if len(nums) > 1 else 0  # J/mol\n",
    "    \n",
    "    # add AECs\n",
    "    energy += get_atom_correction(energy_lot, atoms)  # J/mol\n",
    "    conformer.E0 = (energy / 4184, 'kcal/mol')\n",
    "    \n",
    "    return ScalarQuantity((conformer.get_enthalpy(temp) + conformer.E0.value_si) / 4184, 'kcal/mol')\n",
    "\n",
    "periodic_table = GetPeriodicTable()\n",
    "\n",
    "def log_to_xyz_dict(log):\n",
    "    log = ess_factory(log)\n",
    "    coords, nums, _ = log.load_geometry()\n",
    "    syms = [symbol_by_number[int(n)] for n in nums]\n",
    "    return {\n",
    "        'coords': coords,\n",
    "        'isotopes': [periodic_table.GetMostCommonIsotope(s) for s in syms],\n",
    "        'symbols': syms\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.3) Match all of the reference species to log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_int = re.compile(r'[0-9]+')\n",
    "ref_spcs = {spc.index: spc for spc in database.reference_sets['main']}\n",
    "\n",
    "# Each log file must start with the index followed by an underscore\n",
    "def get_logs(log_dir):\n",
    "    if log_dir is None:\n",
    "        return defaultdict(lambda: None)\n",
    "    \n",
    "    logs = glob.glob(os.path.join(log_dir, '*.out'))\n",
    "    logs.extend(glob.glob(os.path.join(log_dir, '*.log')))\n",
    "    logs = {int(re_int.findall(os.path.basename(log))[0]): log for log in logs}\n",
    "    \n",
    "    num_missing = 0\n",
    "    for missing_idx in ref_spcs.keys() - logs.keys():\n",
    "        print(f'{ref_spcs[missing_idx]} is missing a log file in {log_dir}')\n",
    "        num_missing += 1\n",
    "    print(f'A total of {num_missing} reference species are missing a log file!\\n')    \n",
    "    \n",
    "    return logs\n",
    "    \n",
    "freq_logs = get_logs(freq_log_dir)\n",
    "energy_logs = get_logs(energy_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "assert len(energy_logs) == len(freq_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.4) Compute thermo and update values for the reference species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_iter = freq_logs if energy_log_dir is None else energy_logs\n",
    "for idx in logs_iter.keys():\n",
    "    # Ignore extra logs that we don't have ref species for\n",
    "    if idx not in ref_spcs:\n",
    "        continue\n",
    "    print(idx)\n",
    "    hf298 = log_to_enthalpy(freq_lot, energy_lot, freq_logs[idx], energy_log=energy_logs[idx])\n",
    "    \n",
    "    # Update thermo if already in calculated data\n",
    "    if energy_lot in ref_spcs[idx].calculated_data:  \n",
    "        ref_spcs[idx].calculated_data[energy_lot].thermo_data.H298 = hf298\n",
    "    # Make new calculated data entry otherwise\n",
    "    else:\n",
    "        ref_spcs[idx].calculated_data[energy_lot] = CalculatedDataEntry(ThermoData(H298=hf298), xyz_dict=log_to_xyz_dict(freq_logs[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.5) Save the new enthalpy values to RMG-database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3) Create Arkane input file for BAC fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bac_input = f\"\"\"lot = LevelOfTheory(\n",
    "    method='{method}',\n",
    "    basis='{basis}',\n",
    "    software='{software}'\n",
    ")\n",
    "kwargs = {{\n",
    "    'weighted': False,\n",
    "    'write_to_database': True,\n",
    "    'overwrite': True,\n",
    "}}\n",
    "\n",
    "# Petersson-type\n",
    "bac(\n",
    "    level_of_theory=lot,\n",
    "    bac_type='p',  # Petersson\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "# Melius-type\n",
    "bac(\n",
    "    level_of_theory=lot,\n",
    "    bac_type='m',  # Melius\n",
    "    fit_mol_corr=True,\n",
    "    global_opt=True,\n",
    "    global_opt_iter=5,\n",
    "    **kwargs\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bac_arkane.py\", \"w\") as f:\n",
    "    f.write(bac_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do `python RMG-Py/Arkane.py bac_arkane.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
